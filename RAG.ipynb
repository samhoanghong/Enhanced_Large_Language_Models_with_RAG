{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'dataset2.json',\n",
       " 'cs_si_dataset.csv',\n",
       " 'dataset.csv',\n",
       " 'see.txt',\n",
       " 'dataset.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Arxiv category codes\n",
    "# Source: https://www.kaggle.com/code/artgor/arxiv-metadata-exploration\n",
    "\n",
    "# https://arxiv.org/category_taxonomy\n",
    "# https://info.arxiv.org/help/api/user-manual.html#subject_classifications\n",
    "\n",
    "\n",
    "category_map = {\n",
    "# These created errors when mapping categories to descriptions\n",
    "'acc-phys': 'Accelerator Physics',\n",
    "'adap-org': 'Not available',\n",
    "'q-bio': 'Not available',\n",
    "'cond-mat': 'Not available',\n",
    "'chao-dyn': 'Not available',\n",
    "'patt-sol': 'Not available',\n",
    "'dg-ga': 'Not available',\n",
    "'solv-int': 'Not available',\n",
    "'bayes-an': 'Not available',\n",
    "'comp-gas': 'Not available',\n",
    "'alg-geom': 'Not available',\n",
    "'funct-an': 'Not available',\n",
    "'q-alg': 'Not available',\n",
    "'ao-sci': 'Not available',\n",
    "'atom-ph': 'Atomic Physics',\n",
    "'chem-ph': 'Chemical Physics',\n",
    "'plasm-ph': 'Plasma Physics',\n",
    "'mtrl-th': 'Not available',\n",
    "'cmp-lg': 'Not available',\n",
    "'supr-con': 'Not available',\n",
    "###\n",
    "\n",
    "# Added\n",
    "'econ.GN': 'General Economics', \n",
    "'econ.TH': 'Theoretical Economics', \n",
    "'eess.SY': 'Systems and Control', \n",
    "    \n",
    "'astro-ph': 'Astrophysics',\n",
    "'astro-ph.CO': 'Cosmology and Nongalactic Astrophysics',\n",
    "'astro-ph.EP': 'Earth and Planetary Astrophysics',\n",
    "'astro-ph.GA': 'Astrophysics of Galaxies',\n",
    "'astro-ph.HE': 'High Energy Astrophysical Phenomena',\n",
    "'astro-ph.IM': 'Instrumentation and Methods for Astrophysics',\n",
    "'astro-ph.SR': 'Solar and Stellar Astrophysics',\n",
    "'cond-mat.dis-nn': 'Disordered Systems and Neural Networks',\n",
    "'cond-mat.mes-hall': 'Mesoscale and Nanoscale Physics',\n",
    "'cond-mat.mtrl-sci': 'Materials Science',\n",
    "'cond-mat.other': 'Other Condensed Matter',\n",
    "'cond-mat.quant-gas': 'Quantum Gases',\n",
    "'cond-mat.soft': 'Soft Condensed Matter',\n",
    "'cond-mat.stat-mech': 'Statistical Mechanics',\n",
    "'cond-mat.str-el': 'Strongly Correlated Electrons',\n",
    "'cond-mat.supr-con': 'Superconductivity',\n",
    "'cs.AI': 'Artificial Intelligence',\n",
    "'cs.AR': 'Hardware Architecture',\n",
    "'cs.CC': 'Computational Complexity',\n",
    "'cs.CE': 'Computational Engineering, Finance, and Science',\n",
    "'cs.CG': 'Computational Geometry',\n",
    "'cs.CL': 'Computation and Language',\n",
    "'cs.CR': 'Cryptography and Security',\n",
    "'cs.CV': 'Computer Vision and Pattern Recognition',\n",
    "'cs.CY': 'Computers and Society',\n",
    "'cs.DB': 'Databases',\n",
    "'cs.DC': 'Distributed, Parallel, and Cluster Computing',\n",
    "'cs.DL': 'Digital Libraries',\n",
    "'cs.DM': 'Discrete Mathematics',\n",
    "'cs.DS': 'Data Structures and Algorithms',\n",
    "'cs.ET': 'Emerging Technologies',\n",
    "'cs.FL': 'Formal Languages and Automata Theory',\n",
    "'cs.GL': 'General Literature',\n",
    "'cs.GR': 'Graphics',\n",
    "'cs.GT': 'Computer Science and Game Theory',\n",
    "'cs.HC': 'Human-Computer Interaction',\n",
    "'cs.IR': 'Information Retrieval',\n",
    "'cs.IT': 'Information Theory',\n",
    "'cs.LG': 'Machine Learning',\n",
    "'cs.LO': 'Logic in Computer Science',\n",
    "'cs.MA': 'Multiagent Systems',\n",
    "'cs.MM': 'Multimedia',\n",
    "'cs.MS': 'Mathematical Software',\n",
    "'cs.NA': 'Numerical Analysis',\n",
    "'cs.NE': 'Neural and Evolutionary Computing',\n",
    "'cs.NI': 'Networking and Internet Architecture',\n",
    "'cs.OH': 'Other Computer Science',\n",
    "'cs.OS': 'Operating Systems',\n",
    "'cs.PF': 'Performance',\n",
    "'cs.PL': 'Programming Languages',\n",
    "'cs.RO': 'Robotics',\n",
    "'cs.SC': 'Symbolic Computation',\n",
    "'cs.SD': 'Sound',\n",
    "'cs.SE': 'Software Engineering',\n",
    "'cs.SI': 'Social and Information Networks',\n",
    "'cs.SY': 'Systems and Control',\n",
    "'econ.EM': 'Econometrics',             \n",
    "'eess.AS': 'Audio and Speech Processing',\n",
    "'eess.IV': 'Image and Video Processing',\n",
    "'eess.SP': 'Signal Processing',               \n",
    "'gr-qc': 'General Relativity and Quantum Cosmology',\n",
    "'hep-ex': 'High Energy Physics - Experiment',\n",
    "'hep-lat': 'High Energy Physics - Lattice',\n",
    "'hep-ph': 'High Energy Physics - Phenomenology',\n",
    "'hep-th': 'High Energy Physics - Theory',\n",
    "'math.AC': 'Commutative Algebra',\n",
    "'math.AG': 'Algebraic Geometry',\n",
    "'math.AP': 'Analysis of PDEs',\n",
    "'math.AT': 'Algebraic Topology',\n",
    "'math.CA': 'Classical Analysis and ODEs',\n",
    "'math.CO': 'Combinatorics',\n",
    "'math.CT': 'Category Theory',\n",
    "'math.CV': 'Complex Variables',\n",
    "'math.DG': 'Differential Geometry',\n",
    "'math.DS': 'Dynamical Systems',\n",
    "'math.FA': 'Functional Analysis',\n",
    "'math.GM': 'General Mathematics',\n",
    "'math.GN': 'General Topology',\n",
    "'math.GR': 'Group Theory',\n",
    "'math.GT': 'Geometric Topology',\n",
    "'math.HO': 'History and Overview',\n",
    "'math.IT': 'Information Theory',\n",
    "'math.KT': 'K-Theory and Homology',\n",
    "'math.LO': 'Logic',\n",
    "'math.MG': 'Metric Geometry',\n",
    "'math.MP': 'Mathematical Physics',\n",
    "'math.NA': 'Numerical Analysis',\n",
    "'math.NT': 'Number Theory',\n",
    "'math.OA': 'Operator Algebras',\n",
    "'math.OC': 'Optimization and Control',\n",
    "'math.PR': 'Probability',\n",
    "'math.QA': 'Quantum Algebra',\n",
    "'math.RA': 'Rings and Algebras',\n",
    "'math.RT': 'Representation Theory',\n",
    "'math.SG': 'Symplectic Geometry',\n",
    "'math.SP': 'Spectral Theory',\n",
    "'math.ST': 'Statistics Theory',\n",
    "'math-ph': 'Mathematical Physics',\n",
    "'nlin.AO': 'Adaptation and Self-Organizing Systems',\n",
    "'nlin.CD': 'Chaotic Dynamics',\n",
    "'nlin.CG': 'Cellular Automata and Lattice Gases',\n",
    "'nlin.PS': 'Pattern Formation and Solitons',\n",
    "'nlin.SI': 'Exactly Solvable and Integrable Systems',\n",
    "'nucl-ex': 'Nuclear Experiment',\n",
    "'nucl-th': 'Nuclear Theory',\n",
    "'physics.acc-ph': 'Accelerator Physics',\n",
    "'physics.ao-ph': 'Atmospheric and Oceanic Physics',\n",
    "'physics.app-ph': 'Applied Physics',\n",
    "'physics.atm-clus': 'Atomic and Molecular Clusters',\n",
    "'physics.atom-ph': 'Atomic Physics',\n",
    "'physics.bio-ph': 'Biological Physics',\n",
    "'physics.chem-ph': 'Chemical Physics',\n",
    "'physics.class-ph': 'Classical Physics',\n",
    "'physics.comp-ph': 'Computational Physics',\n",
    "'physics.data-an': 'Data Analysis, Statistics and Probability',\n",
    "'physics.ed-ph': 'Physics Education',\n",
    "'physics.flu-dyn': 'Fluid Dynamics',\n",
    "'physics.gen-ph': 'General Physics',\n",
    "'physics.geo-ph': 'Geophysics',\n",
    "'physics.hist-ph': 'History and Philosophy of Physics',\n",
    "'physics.ins-det': 'Instrumentation and Detectors',\n",
    "'physics.med-ph': 'Medical Physics',\n",
    "'physics.optics': 'Optics',\n",
    "'physics.plasm-ph': 'Plasma Physics',\n",
    "'physics.pop-ph': 'Popular Physics',\n",
    "'physics.soc-ph': 'Physics and Society',\n",
    "'physics.space-ph': 'Space Physics',\n",
    "'q-bio.BM': 'Biomolecules',\n",
    "'q-bio.CB': 'Cell Behavior',\n",
    "'q-bio.GN': 'Genomics',\n",
    "'q-bio.MN': 'Molecular Networks',\n",
    "'q-bio.NC': 'Neurons and Cognition',\n",
    "'q-bio.OT': 'Other Quantitative Biology',\n",
    "'q-bio.PE': 'Populations and Evolution',\n",
    "'q-bio.QM': 'Quantitative Methods',\n",
    "'q-bio.SC': 'Subcellular Processes',\n",
    "'q-bio.TO': 'Tissues and Organs',\n",
    "'q-fin.CP': 'Computational Finance',\n",
    "'q-fin.EC': 'Economics',\n",
    "'q-fin.GN': 'General Finance',\n",
    "'q-fin.MF': 'Mathematical Finance',\n",
    "'q-fin.PM': 'Portfolio Management',\n",
    "'q-fin.PR': 'Pricing of Securities',\n",
    "'q-fin.RM': 'Risk Management',\n",
    "'q-fin.ST': 'Statistical Finance',\n",
    "'q-fin.TR': 'Trading and Market Microstructure',\n",
    "'quant-ph': 'Quantum Physics',\n",
    "'stat.AP': 'Applications',\n",
    "'stat.CO': 'Computation',\n",
    "'stat.ME': 'Methodology',\n",
    "'stat.ML': 'Machine Learning',\n",
    "'stat.OT': 'Other Statistics',\n",
    "'stat.TH': 'Statistics Theory'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586192, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>hep-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>math.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2  0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3  0704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4  0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                                            abstract       categories  \n",
       "0    A fully differential calculation in perturba...           hep-ph  \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...    math.CO cs.CG  \n",
       "2    The evolution of Earth-Moon system is descri...   physics.gen-ph  \n",
       "3    We show that a determinant of Stirling cycle...          math.CO  \n",
       "4    In this paper we show how to compute the $\\L...  math.CA math.FA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/matthewmaddock/nlp-arxiv-dataset-transformers-and-umap\n",
    "\n",
    "# This takes about 1 minute.\n",
    "\n",
    "\n",
    "cols = ['id', 'title', 'abstract', 'categories']\n",
    "data = []\n",
    "file_name = 'dataset/dataset2.json'\n",
    "\n",
    "\n",
    "with open(file_name, encoding='latin-1') as f:\n",
    "    for line in f:\n",
    "        doc = json.loads(line)\n",
    "        lst = [doc['id'], doc['title'], doc['abstract'], doc['categories']]\n",
    "        data.append(lst)\n",
    "\n",
    "df_data = pd.DataFrame(data=data, columns=cols)\n",
    "\n",
    "print(df_data.shape)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>cat_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>Combinatorics, Computational Geometry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>General Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>Combinatorics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "      <td>Classical Analysis and ODEs, Functional Analysis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2  0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3  0704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4  0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                                            abstract       categories  \\\n",
       "0    A fully differential calculation in perturba...           hep-ph   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...    math.CO cs.CG   \n",
       "2    The evolution of Earth-Moon system is descri...   physics.gen-ph   \n",
       "3    We show that a determinant of Stirling cycle...          math.CO   \n",
       "4    In this paper we show how to compute the $\\L...  math.CA math.FA   \n",
       "\n",
       "                                           cat_text  \n",
       "0               High Energy Physics - Phenomenology  \n",
       "1             Combinatorics, Computational Geometry  \n",
       "2                                   General Physics  \n",
       "3                                     Combinatorics  \n",
       "4  Classical Analysis and ODEs, Functional Analysis  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cat_text(x):\n",
    "    \n",
    "    cat_text = ''\n",
    "    \n",
    "    # Put the codes into a list\n",
    "    cat_list = x.split(' ')\n",
    "    \n",
    "    for i, item in enumerate(cat_list):\n",
    "        \n",
    "        cat_name = category_map[item]\n",
    "        \n",
    "        # If there was no description available\n",
    "        # for the category code then don't include it in the text.\n",
    "        if cat_name != 'Not available':\n",
    "            \n",
    "            if i == 0:\n",
    "                cat_text = cat_name\n",
    "            else:\n",
    "                cat_text = cat_text + ', ' + cat_name\n",
    " \n",
    "    # Remove leading and trailing spaces\n",
    "    cat_text = cat_text.strip()\n",
    "    \n",
    "    return cat_text\n",
    "    \n",
    "\n",
    "df_data['cat_text'] = df_data['categories'].apply(get_cat_text)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id: 0704.0002\n",
      "\n",
      "Title: Sparsity-certifying Graph Decompositions\n",
      "\n",
      "Categories: Combinatorics, Computational Geometry\n",
      "\n",
      "Abstract:   We describe a new algorithm, the $(k,\\ell)$-pebble game with colors, and use\n",
      "it obtain a characterization of the family of $(k,\\ell)$-sparse graphs and\n",
      "algorithmic solutions to a family of problems concerning tree decompositions of\n",
      "graphs. Special instances of sparse graphs appear in rigidity theory and have\n",
      "received increased attention in recent years. In particular, our colored\n",
      "pebbles generalize and strengthen the previous results of Lee and Streinu and\n",
      "give a new proof of the Tutte-Nash-Williams characterization of arboricity. We\n",
      "also present a new decomposition that certifies sparsity based on the\n",
      "$(k,\\ell)$-pebble game with colors. Our work also exposes connections between\n",
      "pebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\n",
      "Westermann and Hendrickson.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print details of one paper\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('Id:',df_data.loc[i, 'id'])\n",
    "print()\n",
    "print('Title:',df_data.loc[i, 'title'])\n",
    "print()\n",
    "print('Categories:',df_data.loc[i, 'cat_text'])\n",
    "print()\n",
    "print('Abstract:',df_data.loc[i, 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace newline characters ('\\n') with a space\n",
    "# Remove leading and trailing spaces\n",
    "\n",
    "def clean_text(x):\n",
    "    \n",
    "    # Replace newline characters with a space\n",
    "    new_text = x.replace(\"\\n\", \" \")\n",
    "    # Remove leading and trailing spaces\n",
    "    new_text = new_text.strip()\n",
    "    \n",
    "    return new_text\n",
    "\n",
    "df_data['title'] = df_data['title'].apply(clean_text)\n",
    "df_data['abstract'] = df_data['abstract'].apply(clean_text)\n",
    "\n",
    "#df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the title to the abstract\n",
    "\n",
    "df_data['prepared_text'] = df_data['title'] + ' {title} ' + df_data['abstract']\n",
    "\n",
    "#df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586192\n",
      "2586192\n",
      "2586192\n"
     ]
    }
   ],
   "source": [
    "# Create a list of text chunks\n",
    "\n",
    "chunk_list = list(df_data['prepared_text'])\n",
    "\n",
    "# The ids are used to create web links to each paper.\n",
    "# You can access each paper directly on ArXiv using these links:\n",
    "# https://arxiv.org/abs/{id}: ArXiv page for the paper\n",
    "# https://arxiv.org/pdf/{id}: Direct link to download the PDF\n",
    "\n",
    "arxiv_id_list = list(df_data['id'])\n",
    "cat_list = list(df_data['cat_text'])\n",
    "\n",
    "print(len(chunk_list))\n",
    "print(len(arxiv_id_list))\n",
    "print(len(cat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calculation of prompt diphoton production cross sections at Tevatron and   LHC energies {title} A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. All next-to-leading order perturbative contributions from quark-antiquark, gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as all-orders resummation of initial-state gluon radiation valid at next-to-next-to-leading logarithmic accuracy. The region of phase space is specified in which the calculation is most reliable. Good agreement is demonstrated with data from the Fermilab Tevatron, and predictions are made for more detailed tests with CDF and DO data. Predictions are shown for distributions of diphoton pairs produced at the energy of the Large Hadron Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs boson are contrasted with those produced from QCD processes at the LHC, showing that enhanced sensitivity to the signal can be obtained with judicious selection of events.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586192, 384)\n",
      "Embedding length 384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(chunk_list)\n",
    "\n",
    "print(embeddings.shape)\n",
    "print('Embedding length', embeddings.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG copy.ipynb\n",
      "RAG.ipynb\n",
      "Untitled Diagram.pdf\n",
      "[ENSF 619.5] Social dimensions of technologies in computer & society articles.pdf\n",
      "apigemini.txt\n",
      "arxiv-metadata-oai-snapshot-2.json\n",
      "compressed_array.npz\n",
      "compressed_dataframe.csv\n",
      "compressed_dataframe.csv.gz\n",
      "\u001b[34mdataset\u001b[m\u001b[m\n",
      "datasetconvert.py\n",
      "differences.txt\n",
      "filter.py\n",
      "filtered_differences.txt\n",
      "runsystem.ipynb\n",
      "see.ipynb\n",
      "systemapi.py\n",
      "\u001b[34mtest\u001b[m\u001b[m\n",
      "testapigemini.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Save the array in compressed format\n",
    "np.savez_compressed('compressed_array.npz', array_data=embeddings)\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 3512.1689653396606 MB\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the saved file\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the size of the file in bytes\n",
    "file_size_bytes = os.path.getsize('compressed_array.npz')\n",
    "\n",
    "# Convert bytes to megabytes\n",
    "file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(\"File size:\", file_size_mb, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2586192, 384)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to load the saved array\n",
    "\n",
    "# Load the compressed array\n",
    "loaded_embeddings = np.load('compressed_array.npz')\n",
    "\n",
    "# Access the array by the name you specified ('my_array' in this case)\n",
    "loaded_embeddings = loaded_embeddings['array_data']\n",
    "\n",
    "loaded_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG copy.ipynb\n",
      "RAG.ipynb\n",
      "Untitled Diagram.pdf\n",
      "[ENSF 619.5] Social dimensions of technologies in computer & society articles.pdf\n",
      "apigemini.txt\n",
      "arxiv-metadata-oai-snapshot-2.json\n",
      "compressed_array.npz\n",
      "compressed_dataframe.csv\n",
      "compressed_dataframe.csv.gz\n",
      "\u001b[34mdataset\u001b[m\u001b[m\n",
      "datasetconvert.py\n",
      "differences.txt\n",
      "filter.py\n",
      "filtered_differences.txt\n",
      "runsystem.ipynb\n",
      "see.ipynb\n",
      "systemapi.py\n",
      "\u001b[34mtest\u001b[m\u001b[m\n",
      "testapigemini.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame in compressed format\n",
    "\n",
    "df_data.to_csv('compressed_dataframe.csv.gz', compression='gzip', index=False)\n",
    "\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9w/bvj8jnnd4979ylmj01tbvy8w0000gn/T/ipykernel_1785/3566718505.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('compressed_dataframe.csv.gz', compression='gzip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2586192, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>cat_text</th>\n",
       "      <th>prepared_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturbati...</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-pe...</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>Combinatorics, Computational Geometry</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions {titl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  704.0001  Calculation of prompt diphoton production cros...   \n",
       "1  704.0002           Sparsity-certifying Graph Decompositions   \n",
       "\n",
       "                                            abstract     categories  \\\n",
       "0  A fully differential calculation in perturbati...         hep-ph   \n",
       "1  We describe a new algorithm, the $(k,\\ell)$-pe...  math.CO cs.CG   \n",
       "\n",
       "                                cat_text  \\\n",
       "0    High Energy Physics - Phenomenology   \n",
       "1  Combinatorics, Computational Geometry   \n",
       "\n",
       "                                       prepared_text  \n",
       "0  Calculation of prompt diphoton production cros...  \n",
       "1  Sparsity-certifying Graph Decompositions {titl...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to load the compressed DataFrame\n",
    "\n",
    "df = pd.read_csv('compressed_dataframe.csv.gz', compression='gzip')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "embed_length = embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(embed_length)\n",
    "\n",
    "# Check if the index is trained.\n",
    "# No training needed when using greedy search i.e. IndexFlatL2\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2586192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the embeddings to the index\n",
    "\n",
    "index.add(loaded_embeddings)\n",
    "\n",
    "# Check the total number of embeddings in the index\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1182973 1417302  191803]]\n",
      "[[0.7161845 0.8309304 0.8536004]]\n"
     ]
    }
   ],
   "source": [
    "# Run a query\n",
    "\n",
    "# query_text = \"\"\"\n",
    "# I want to create an invisibility cloak similar to the one in Harry Potter.\n",
    "# \"\"\"\n",
    "query_text = \"\"\" \n",
    "I want to read some papers about facial recognition and its social issue\n",
    "\"\"\"\n",
    "query = [query_text]\n",
    "\n",
    "\n",
    "# Vectorize the query string\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "# Set the number of outputs we want\n",
    "top_k = 3\n",
    "\n",
    "# Run the query\n",
    "# index_vals refers to the chunk_list index values\n",
    "scores, index_vals = index.search(query_embedding, top_k)\n",
    "\n",
    "print(index_vals)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Responsible Facial Recognition and Beyond {title} Facial recognition is changing the way we live in and interact with our society. Here we discuss the two sides of facial recognition, summarizing potential risks and current concerns. We introduce current policies and regulations in different countries. Very importantly, we point out that the risks and concerns are not only from facial recognition, but also realistically very similar to other biometric recognition technology, including but not limited to gait recognition, iris recognition, fingerprint recognition, voice recognition, etc. To create a responsible future, we discuss possible technological moves and efforts that should be made to keep facial recognition (and biometric recognition in general) developing for social good.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the first search result\n",
    "\n",
    "pred_indexes = index_vals[0]\n",
    "\n",
    "i = 0\n",
    "chunk_index = pred_indexes[i]\n",
    "text = chunk_list[chunk_index]\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neigbor Search in investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How many clusters (voronoid cells) do we want?\n",
    "# # Example: For 4 centroilds we need at least 156 embeddings in\n",
    "# # order to train the index.\n",
    "# num_centroids = 5\n",
    "\n",
    "# quantizer = faiss.IndexFlatL2(embed_length)\n",
    "\n",
    "# index = faiss.IndexIVFFlat(quantizer, embed_length, num_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the index\n",
    "# # After the index is trained it's ready to receive data\n",
    "\n",
    "# index.train(loaded_embeddings)\n",
    "\n",
    "# index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the embeddings to the index\n",
    "\n",
    "# index.add(embeddings)\n",
    "\n",
    "# # Check how many embeddings are in the index\n",
    "# index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = [query_text]\n",
    "# query_embedding = model.encode(query)\n",
    "\n",
    "# top_k = 5\n",
    "\n",
    "\n",
    "# # Run the query\n",
    "# # index_vals refers to the chunk_list index values\n",
    "# scores, index_vals = index.search(query_embedding, top_k)\n",
    "\n",
    "# print(index_vals)\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's print the first search result\n",
    "\n",
    "# pred_indexes = index_vals[0]\n",
    "\n",
    "# i = 3\n",
    "# chunk_index = pred_indexes[i]\n",
    "# text = chunk_list[chunk_index]\n",
    "\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # So far we've just been searching the cell with \n",
    "# # the nearest centroid.\n",
    "# # Setting nprobe allows us to search more of\n",
    "# # the nearest cells. e.g. nprobe = 4 means w will search 4 cells.\n",
    "# # This can be done if we were not getting good results and wanted\n",
    "# # to improve performance. The time taken also increases as we are\n",
    "# # comparing to more vectors.\n",
    "\n",
    "# index.nprobe = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = [query_text]\n",
    "# query_embedding = model.encode(query)\n",
    "\n",
    "# top_k = 5\n",
    "\n",
    "# # Run the query\n",
    "# # index_vals refers to the chunk_list index values\n",
    "# scores, index_vals = index.search(query_embedding, top_k)\n",
    "\n",
    "# print(index_vals)\n",
    "# print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's print the third search result\n",
    "\n",
    "# pred_indexes = index_vals[0]\n",
    "\n",
    "# i = 3\n",
    "# chunk_index = pred_indexes[i]\n",
    "# text = chunk_list[chunk_index]\n",
    "\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# We use a cross-encoder to re-rank the results\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(1182973),\n",
       " np.int64(1417302),\n",
       " np.int64(191803),\n",
       " np.int64(1334997),\n",
       " np.int64(1574334),\n",
       " np.int64(1383220),\n",
       " np.int64(1579102),\n",
       " np.int64(799967),\n",
       " np.int64(1363353),\n",
       " np.int64(1754843)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1] Run a search\n",
    "\n",
    "query = [query_text]\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "top_k = 10\n",
    "D, I = index.search(query_embedding, top_k)\n",
    "\n",
    "list(I[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Responsible Facial Recognition and Beyond {title} Facial recognition is changing the way we live in and interact with our society. Here we discuss the two sides of facial recognition, summarizing potential risks and current concerns. We introduce current policies and regulations in different countries. Very importantly, we point out that the risks and concerns are not only from facial recognition, but also realistically very similar to other biometric recognition technology, including but not limited to gait recognition, iris recognition, fingerprint recognition, voice recognition, etc. To create a responsible future, we discuss possible technological moves and efforts that should be made to keep facial recognition (and biometric recognition in general) developing for social good.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2] Get the text associated with each search result\n",
    "\n",
    "pred_list = list(I[0])\n",
    "\n",
    "# Replace the chunk index values with the corresponding strings\n",
    "pred_strings_list = [chunk_list[item] for item in pred_list]\n",
    "\n",
    "pred_strings_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the input for the cross encoder\n",
    "\n",
    "# The input to the cross_encoder is a list of lists\n",
    "# [[query_text, pred_text1], [query_text, pred_text2], ...]\n",
    "\n",
    "cross_input_list = []\n",
    "\n",
    "for item in pred_strings_list:\n",
    "    \n",
    "    new_list = [query[0], item]\n",
    "    \n",
    "    cross_input_list.append(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \\nI want to read some papers about facial recognition and its social issue\\n',\n",
       " 'Facial Recognition Technology: An analysis with scope in India {title} A facial recognition system is a computer application for automatically identifying or verifying a person from a digital image or a video frame from a video source. One of the way is to do this is by comparing selected facial features from the image and a facial database.It is typically used in security systems and can be compared to other biometrics such as fingerprint or eye iris recognition systems. In this paper we focus on 3-D facial recognition system and biometric facial recognision system. We do critics on facial recognision system giving effectiveness and weaknesses. This paper also introduces scope of recognision system in India.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_input_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>original_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Responsible Facial Recognition and Beyond {tit...</td>\n",
       "      <td>1182973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>About Face: A Survey of Facial Recognition Eva...</td>\n",
       "      <td>1417302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Facial Recognition Technology: An analysis wit...</td>\n",
       "      <td>191803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Facial Recognition: A cross-national Survey on...</td>\n",
       "      <td>1334997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>SoK: Anti-Facial Recognition Technology {title...</td>\n",
       "      <td>1574334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0   \\nI want to read some papers about facial rec...   \n",
       "1   \\nI want to read some papers about facial rec...   \n",
       "2   \\nI want to read some papers about facial rec...   \n",
       "3   \\nI want to read some papers about facial rec...   \n",
       "4   \\nI want to read some papers about facial rec...   \n",
       "\n",
       "                                           pred_text  original_index  \n",
       "0  Responsible Facial Recognition and Beyond {tit...         1182973  \n",
       "1  About Face: A Survey of Facial Recognition Eva...         1417302  \n",
       "2  Facial Recognition Technology: An analysis wit...          191803  \n",
       "3  Facial Recognition: A cross-national Survey on...         1334997  \n",
       "4  SoK: Anti-Facial Recognition Technology {title...         1574334  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the pred text into a dataframe\n",
    "\n",
    "df = pd.DataFrame(cross_input_list, columns=['query_text', 'pred_text'])\n",
    "df['original_index'] = I[0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8622672, -3.610136 , -3.691679 ,  0.3292061, -1.1912436,\n",
       "       -3.9569216, -7.8567657, -5.4584627, -0.8588654, -5.335023 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, score all retrieved passages using the cross_encoder\n",
    "\n",
    "cross_scores = cross_encoder.predict(cross_input_list)\n",
    "\n",
    "cross_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>original_index</th>\n",
       "      <th>cross_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Responsible Facial Recognition and Beyond {tit...</td>\n",
       "      <td>1182973</td>\n",
       "      <td>0.862267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>About Face: A Survey of Facial Recognition Eva...</td>\n",
       "      <td>1417302</td>\n",
       "      <td>-3.610136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Facial Recognition Technology: An analysis wit...</td>\n",
       "      <td>191803</td>\n",
       "      <td>-3.691679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Facial Recognition: A cross-national Survey on...</td>\n",
       "      <td>1334997</td>\n",
       "      <td>0.329206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>SoK: Anti-Facial Recognition Technology {title...</td>\n",
       "      <td>1574334</td>\n",
       "      <td>-1.191244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0   \\nI want to read some papers about facial rec...   \n",
       "1   \\nI want to read some papers about facial rec...   \n",
       "2   \\nI want to read some papers about facial rec...   \n",
       "3   \\nI want to read some papers about facial rec...   \n",
       "4   \\nI want to read some papers about facial rec...   \n",
       "\n",
       "                                           pred_text  original_index  \\\n",
       "0  Responsible Facial Recognition and Beyond {tit...         1182973   \n",
       "1  About Face: A Survey of Facial Recognition Eva...         1417302   \n",
       "2  Facial Recognition Technology: An analysis wit...          191803   \n",
       "3  Facial Recognition: A cross-national Survey on...         1334997   \n",
       "4  SoK: Anti-Facial Recognition Technology {title...         1574334   \n",
       "\n",
       "   cross_scores  \n",
       "0      0.862267  \n",
       "1     -3.610136  \n",
       "2     -3.691679  \n",
       "3      0.329206  \n",
       "4     -1.191244  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the scores to the dataframe\n",
    "\n",
    "df['cross_scores'] = cross_scores\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>original_index</th>\n",
       "      <th>cross_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Responsible Facial Recognition and Beyond {tit...</td>\n",
       "      <td>1182973</td>\n",
       "      <td>0.862267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Facial Recognition: A cross-national Survey on...</td>\n",
       "      <td>1334997</td>\n",
       "      <td>0.329206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Understanding bias in facial recognition techn...</td>\n",
       "      <td>1363353</td>\n",
       "      <td>-0.858865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>SoK: Anti-Facial Recognition Technology {title...</td>\n",
       "      <td>1574334</td>\n",
       "      <td>-1.191244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>About Face: A Survey of Facial Recognition Eva...</td>\n",
       "      <td>1417302</td>\n",
       "      <td>-3.610136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Facial Recognition Technology: An analysis wit...</td>\n",
       "      <td>191803</td>\n",
       "      <td>-3.691679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>GenderRobustness: Robustness of Gender Detecti...</td>\n",
       "      <td>1383220</td>\n",
       "      <td>-3.956922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Robustness Disparities in Face Detection {titl...</td>\n",
       "      <td>1754843</td>\n",
       "      <td>-5.335023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Automated Inference on Sociopsychological Impr...</td>\n",
       "      <td>799967</td>\n",
       "      <td>-5.458463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nI want to read some papers about facial rec...</td>\n",
       "      <td>Cinderella's shoe won't fit Soundarya: An audi...</td>\n",
       "      <td>1579102</td>\n",
       "      <td>-7.856766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text  \\\n",
       "0   \\nI want to read some papers about facial rec...   \n",
       "1   \\nI want to read some papers about facial rec...   \n",
       "2   \\nI want to read some papers about facial rec...   \n",
       "3   \\nI want to read some papers about facial rec...   \n",
       "4   \\nI want to read some papers about facial rec...   \n",
       "5   \\nI want to read some papers about facial rec...   \n",
       "6   \\nI want to read some papers about facial rec...   \n",
       "7   \\nI want to read some papers about facial rec...   \n",
       "8   \\nI want to read some papers about facial rec...   \n",
       "9   \\nI want to read some papers about facial rec...   \n",
       "\n",
       "                                           pred_text  original_index  \\\n",
       "0  Responsible Facial Recognition and Beyond {tit...         1182973   \n",
       "1  Facial Recognition: A cross-national Survey on...         1334997   \n",
       "2  Understanding bias in facial recognition techn...         1363353   \n",
       "3  SoK: Anti-Facial Recognition Technology {title...         1574334   \n",
       "4  About Face: A Survey of Facial Recognition Eva...         1417302   \n",
       "5  Facial Recognition Technology: An analysis wit...          191803   \n",
       "6  GenderRobustness: Robustness of Gender Detecti...         1383220   \n",
       "7  Robustness Disparities in Face Detection {titl...         1754843   \n",
       "8  Automated Inference on Sociopsychological Impr...          799967   \n",
       "9  Cinderella's shoe won't fit Soundarya: An audi...         1579102   \n",
       "\n",
       "   cross_scores  \n",
       "0      0.862267  \n",
       "1      0.329206  \n",
       "2     -0.858865  \n",
       "3     -1.191244  \n",
       "4     -3.610136  \n",
       "5     -3.691679  \n",
       "6     -3.956922  \n",
       "7     -5.335023  \n",
       "8     -5.458463  \n",
       "9     -7.856766  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the DataFrame in descending order based on the scores\n",
    "\n",
    "df_sorted = df.sort_values(by='cross_scores', ascending=False)\n",
    "\n",
    "# Reset the index (*This was missed previously*)\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "\n",
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original order: [1182973 1417302  191803 1334997 1574334 1383220 1579102  799967 1363353\n",
      " 1754843]\n",
      "Reranked order: [1182973, 1334997, 1363353, 1574334, 1417302, 191803, 1383220, 1754843, 799967, 1579102]\n"
     ]
    }
   ],
   "source": [
    "# Compare the orginal predicted index order and \n",
    "# the re-ranked index order\n",
    "\n",
    "print('Original order:',I[0])\n",
    "print('Reranked order:',list(df_sorted['original_index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link to pdf: https://arxiv.org/pdf/1909.12935\n",
      "Categories: Computer Vision and Pattern Recognition, Computers and Society\n",
      "Abstract: Responsible Facial Recognition and Beyond {title} Facial recognition is changing the way we live in and interact with our society. Here we discuss the two sides of facial recognition, summarizing potential risks and current concerns. We introduce current policies and regulations in different countries. Very importantly, we point out that the risks and concerns are not only from facial recognition, but also realistically very similar to other biometric recognition technology, including but not limited to gait recognition, iris recognition, fingerprint recognition, voice recognition, etc. To create a responsible future, we discuss possible technological moves and efforts that should be made to keep facial recognition (and biometric recognition in general) developing for social good.\n",
      "\n",
      "Link to pdf: https://arxiv.org/pdf/2008.07275\n",
      "Categories: Computers and Society, Computer Vision and Pattern Recognition, Machine Learning, Machine Learning\n",
      "Abstract: Facial Recognition: A cross-national Survey on Public Acceptance,   Privacy, and Discrimination {title} With rapid advances in machine learning (ML), more of this technology is being deployed into the real world interacting with us and our environment. One of the most widely applied application of ML is facial recognition as it is running on millions of devices. While being useful for some people, others perceive it as a threat when used by public authorities. This discrepancy and the lack of policy increases the uncertainty in the ML community about the future direction of facial recognition research and development. In this paper we present results from a cross-national survey about public acceptance, privacy, and discrimination of the use of facial recognition technology (FRT) in the public. This study provides insights about the opinion towards FRT from China, Germany, the United Kingdom (UK), and the United States (US), which can serve as input for policy makers and legal regulators.\n",
      "\n",
      "Link to pdf: https://arxiv.org/pdf/2010.07023\n",
      "Categories: Computers and Society, Computer Vision and Pattern Recognition, Databases\n",
      "Abstract: Understanding bias in facial recognition technologies {title} Over the past couple of years, the growing debate around automated facial recognition has reached a boiling point. As developers have continued to swiftly expand the scope of these kinds of technologies into an almost unbounded range of applications, an increasingly strident chorus of critical voices has sounded concerns about the injurious effects of the proliferation of such systems. Opponents argue that the irresponsible design and use of facial detection and recognition technologies (FDRTs) threatens to violate civil liberties, infringe on basic human rights and further entrench structural racism and systemic marginalisation. They also caution that the gradual creep of face surveillance infrastructures into every domain of lived experience may eventually eradicate the modern democratic forms of life that have long provided cherished means to individual flourishing, social solidarity and human self-creation. Defenders, by contrast, emphasise the gains in public safety, security and efficiency that digitally streamlined capacities for facial identification, identity verification and trait characterisation may bring. In this explainer, I focus on one central aspect of this debate: the role that dynamics of bias and discrimination play in the development and deployment of FDRTs. I examine how historical patterns of discrimination have made inroads into the design and implementation of FDRTs from their very earliest moments. And, I explain the ways in which the use of biased FDRTs can lead distributional and recognitional injustices. The explainer concludes with an exploration of broader ethical questions around the potential proliferation of pervasive face-based surveillance infrastructures and makes some recommendations for cultivating more responsible approaches to the development and governance of these technologies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the output\n",
    "\n",
    "# Print three results\n",
    "num_results = 3\n",
    "\n",
    "for i in range(0,num_results):\n",
    "    \n",
    "    text = df_sorted.loc[i, 'pred_text']\n",
    "    \n",
    "    original_index = df_sorted.loc[i, 'original_index']\n",
    "    arxiv_id = df_data.loc[original_index, 'id']\n",
    "    cat_text = df_data.loc[original_index, 'cat_text']\n",
    "    \n",
    "    # Crete the link to the research paper pdf\n",
    "    link_to_pdf = f'https://arxiv.org/pdf/{arxiv_id}'\n",
    "    \n",
    "    print('Link to pdf:',link_to_pdf)\n",
    "    print('Categories:',cat_text)\n",
    "    print('Abstract:',text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBc44ipiYJ_mU0AWlvbp9OQN5Ntwlcbn_Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 3 search results\n",
    "pred_text_list = list(df_sorted['pred_text'])\n",
    "context = pred_text_list[0:3]\n",
    "\n",
    "# Create the prompt\n",
    "\n",
    "# prompt = f\"\"\"\n",
    "# You will be provided with a list of titles and abstracts \n",
    "# for research papers: \n",
    "# {context}\n",
    "# Write a one sentence summary of each abstract at the level \n",
    "# of a high school student.\n",
    "# \"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with a list of titles and abstracts \n",
    "for research papers: \n",
    "{context}\n",
    "Write a one sentence to represent if the authors arguments about facial recognitions technologies are positive or negative, based on the abstract\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first two abstracts present a largely negative view of facial recognition technology, highlighting risks and concerns, while the third abstract presents a mixed view, acknowledging both potential benefits and significant ethical concerns related to bias and discrimination.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next steps\n",
    "\n",
    "#improve the RAG model\n",
    "#make a new notebook to just run the query\n",
    "#UX/UI\n",
    "#maybe: pdf web-mining the content\n",
    "#maybe: automatically update the new data available on Kaggle\n",
    "#security to store the api key file using fernet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
